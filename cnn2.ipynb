{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 20 categoies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories: 101\n",
      "Categories:\n",
      "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and destination paths\n",
    "source_path = '/Users/ruoqiyan/Desktop/690ML/ml_project/data/images/'\n",
    "# Get a list of all subdirectories (categories)\n",
    "categories = sorted([d for d in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, d))])\n",
    "\n",
    "print(f\"Total Categories: {len(categories)}\")\n",
    "print(\"Categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/ruoqiyan/Desktop/690ML/ml_project/food_20_data/images/apple_pie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, category)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(src):\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset reduced to 20 categories!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:561\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    560\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/shutil.py:459\u001b[0m, in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     ignored_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 459\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    461\u001b[0m use_srcentry \u001b[38;5;241m=\u001b[39m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy2 \u001b[38;5;129;01mor\u001b[39;00m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/ruoqiyan/Desktop/690ML/ml_project/food_20_data/images/apple_pie'"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/ruoqiyan/Desktop/690ML/ml_project/food_20_data/images/'\n",
    "\n",
    "# select 20 categories\n",
    "selected_categories = categories[0:20]\n",
    "\n",
    "# Create destination directory if not exists\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Copy selected categories to the new dataset folder\n",
    "for category in selected_categories:\n",
    "    src = os.path.join(source_path, category)\n",
    "    dst = os.path.join(data_path, category)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copytree(src, dst)\n",
    "print(\"Dataset reduced to 20 categories!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 20 classes.\n",
      "Found 4000 images belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 149, 149, 32)         864       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_188 (B  (None, 149, 149, 32)         96        ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_188 (Activation  (None, 149, 149, 32)         0         ['batch_normalization_188[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 147, 147, 32)         9216      ['activation_188[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_189 (B  (None, 147, 147, 32)         96        ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_189 (Activation  (None, 147, 147, 32)         0         ['batch_normalization_189[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)         (None, 147, 147, 64)         18432     ['activation_189[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_190 (B  (None, 147, 147, 64)         192       ['conv2d_190[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 147, 147, 64)         0         ['batch_normalization_190[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 73, 73, 64)           0         ['activation_190[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)         (None, 73, 73, 80)           5120      ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_191 (B  (None, 73, 73, 80)           240       ['conv2d_191[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 73, 73, 80)           0         ['batch_normalization_191[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)         (None, 71, 71, 192)          138240    ['activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_192 (B  (None, 71, 71, 192)          576       ['conv2d_192[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 71, 71, 192)          0         ['batch_normalization_192[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 35, 35, 192)          0         ['activation_192[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)         (None, 35, 35, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 35, 35, 64)           192       ['conv2d_196[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_196[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)         (None, 35, 35, 48)           9216      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)         (None, 35, 35, 96)           55296     ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_194 (B  (None, 35, 35, 48)           144       ['conv2d_194[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 35, 35, 96)           288       ['conv2d_197[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 35, 35, 48)           0         ['batch_normalization_194[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_197[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_18 (Aver  (None, 35, 35, 192)          0         ['max_pooling2d_9[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)         (None, 35, 35, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)         (None, 35, 35, 64)           76800     ['activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)         (None, 35, 35, 96)           82944     ['activation_197[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 35, 35, 32)           6144      ['average_pooling2d_18[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_193 (B  (None, 35, 35, 64)           192       ['conv2d_193[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (B  (None, 35, 35, 64)           192       ['conv2d_195[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 35, 35, 96)           288       ['conv2d_198[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 35, 35, 32)           96        ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_193[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_195[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 35, 35, 32)           0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 35, 35, 256)          0         ['activation_193[0][0]',      \n",
      "                                                                     'activation_195[0][0]',      \n",
      "                                                                     'activation_198[0][0]',      \n",
      "                                                                     'activation_199[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)         (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 35, 35, 64)           192       ['conv2d_203[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_203 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 35, 35, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)         (None, 35, 35, 96)           55296     ['activation_203[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 35, 35, 48)           144       ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 35, 35, 96)           288       ['conv2d_204[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_201 (Activation  (None, 35, 35, 48)           0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_204 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_19 (Aver  (None, 35, 35, 256)          0         ['mixed0[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)         (None, 35, 35, 64)           76800     ['activation_201[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)         (None, 35, 35, 96)           82944     ['activation_204[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)         (None, 35, 35, 64)           16384     ['average_pooling2d_19[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 35, 35, 64)           192       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 35, 35, 64)           192       ['conv2d_202[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 35, 35, 96)           288       ['conv2d_205[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 35, 35, 64)           192       ['conv2d_206[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_200 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_202 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_205 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_206 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 35, 35, 288)          0         ['activation_200[0][0]',      \n",
      "                                                                     'activation_202[0][0]',      \n",
      "                                                                     'activation_205[0][0]',      \n",
      "                                                                     'activation_206[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)         (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_210 (B  (None, 35, 35, 64)           192       ['conv2d_210[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_210 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_210[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)         (None, 35, 35, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)         (None, 35, 35, 96)           55296     ['activation_210[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_208 (B  (None, 35, 35, 48)           144       ['conv2d_208[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_211 (B  (None, 35, 35, 96)           288       ['conv2d_211[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_208 (Activation  (None, 35, 35, 48)           0         ['batch_normalization_208[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_211 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_211[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (Aver  (None, 35, 35, 288)          0         ['mixed1[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)         (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)         (None, 35, 35, 64)           76800     ['activation_208[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)         (None, 35, 35, 96)           82944     ['activation_211[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)         (None, 35, 35, 64)           18432     ['average_pooling2d_20[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 35, 35, 64)           192       ['conv2d_207[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_209 (B  (None, 35, 35, 64)           192       ['conv2d_209[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_212 (B  (None, 35, 35, 96)           288       ['conv2d_212[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_213 (B  (None, 35, 35, 64)           192       ['conv2d_213[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_207 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_209 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_209[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_212 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_212[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_213 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_213[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 35, 35, 288)          0         ['activation_207[0][0]',      \n",
      "                                                                     'activation_209[0][0]',      \n",
      "                                                                     'activation_212[0][0]',      \n",
      "                                                                     'activation_213[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)         (None, 35, 35, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_215 (B  (None, 35, 35, 64)           192       ['conv2d_215[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_215 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_215[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)         (None, 35, 35, 96)           55296     ['activation_215[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_216 (B  (None, 35, 35, 96)           288       ['conv2d_216[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_216 (Activation  (None, 35, 35, 96)           0         ['batch_normalization_216[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)         (None, 17, 17, 384)          995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)         (None, 17, 17, 96)           82944     ['activation_216[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_214 (B  (None, 17, 17, 384)          1152      ['conv2d_214[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_217 (B  (None, 17, 17, 96)           288       ['conv2d_217[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_214 (Activation  (None, 17, 17, 384)          0         ['batch_normalization_214[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_217 (Activation  (None, 17, 17, 96)           0         ['batch_normalization_217[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 17, 17, 288)          0         ['mixed2[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 17, 17, 768)          0         ['activation_214[0][0]',      \n",
      "                                                                     'activation_217[0][0]',      \n",
      "                                                                     'max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)         (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 17, 17, 128)          384       ['conv2d_222[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_222 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_222[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)         (None, 17, 17, 128)          114688    ['activation_222[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 17, 17, 128)          384       ['conv2d_223[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_223 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_223[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)         (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)         (None, 17, 17, 128)          114688    ['activation_223[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_219 (B  (None, 17, 17, 128)          384       ['conv2d_219[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_224 (B  (None, 17, 17, 128)          384       ['conv2d_224[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_219 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_219[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_224 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_224[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)         (None, 17, 17, 128)          114688    ['activation_219[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)         (None, 17, 17, 128)          114688    ['activation_224[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_220 (B  (None, 17, 17, 128)          384       ['conv2d_220[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_225 (B  (None, 17, 17, 128)          384       ['conv2d_225[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_220 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_220[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_225 (Activation  (None, 17, 17, 128)          0         ['batch_normalization_225[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (Aver  (None, 17, 17, 768)          0         ['mixed3[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)         (None, 17, 17, 192)          172032    ['activation_220[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)         (None, 17, 17, 192)          172032    ['activation_225[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)         (None, 17, 17, 192)          147456    ['average_pooling2d_21[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_218 (B  (None, 17, 17, 192)          576       ['conv2d_218[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_221 (B  (None, 17, 17, 192)          576       ['conv2d_221[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (B  (None, 17, 17, 192)          576       ['conv2d_226[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_227 (B  (None, 17, 17, 192)          576       ['conv2d_227[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_218 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_218[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_221 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_221[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_226 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_226[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_227 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_227[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 17, 17, 768)          0         ['activation_218[0][0]',      \n",
      "                                                                     'activation_221[0][0]',      \n",
      "                                                                     'activation_226[0][0]',      \n",
      "                                                                     'activation_227[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)         (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_232 (B  (None, 17, 17, 160)          480       ['conv2d_232[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_232 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_232[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_232[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_233 (B  (None, 17, 17, 160)          480       ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_233 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_233[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)         (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_233[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_229 (B  (None, 17, 17, 160)          480       ['conv2d_229[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_234 (B  (None, 17, 17, 160)          480       ['conv2d_234[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_229 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_229[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_234 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_234[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_229[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_234[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_230 (B  (None, 17, 17, 160)          480       ['conv2d_230[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_235 (B  (None, 17, 17, 160)          480       ['conv2d_235[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_230 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_230[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_235 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_235[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (Aver  (None, 17, 17, 768)          0         ['mixed4[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)         (None, 17, 17, 192)          215040    ['activation_230[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 17, 17, 192)          215040    ['activation_235[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 17, 17, 192)          147456    ['average_pooling2d_22[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_228 (B  (None, 17, 17, 192)          576       ['conv2d_228[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_231 (B  (None, 17, 17, 192)          576       ['conv2d_231[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_236 (B  (None, 17, 17, 192)          576       ['conv2d_236[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_237 (B  (None, 17, 17, 192)          576       ['conv2d_237[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_228 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_228[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_231 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_231[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_236 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_236[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_237 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_237[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 17, 17, 768)          0         ['activation_228[0][0]',      \n",
      "                                                                     'activation_231[0][0]',      \n",
      "                                                                     'activation_236[0][0]',      \n",
      "                                                                     'activation_237[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_242 (B  (None, 17, 17, 160)          480       ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_242 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_242[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_242[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_243 (B  (None, 17, 17, 160)          480       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_243 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_243[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_243[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_239 (B  (None, 17, 17, 160)          480       ['conv2d_239[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_244 (B  (None, 17, 17, 160)          480       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_239 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_239[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_244 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_244[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_239[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 17, 17, 160)          179200    ['activation_244[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_240 (B  (None, 17, 17, 160)          480       ['conv2d_240[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_245 (B  (None, 17, 17, 160)          480       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_240 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_240[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_245 (Activation  (None, 17, 17, 160)          0         ['batch_normalization_245[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (Aver  (None, 17, 17, 768)          0         ['mixed5[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 17, 17, 192)          215040    ['activation_240[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 17, 17, 192)          215040    ['activation_245[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 17, 17, 192)          147456    ['average_pooling2d_23[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_238 (B  (None, 17, 17, 192)          576       ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_241 (B  (None, 17, 17, 192)          576       ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_246 (B  (None, 17, 17, 192)          576       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_247 (B  (None, 17, 17, 192)          576       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_238 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_238[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_241 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_241[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_246 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_246[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_247 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_247[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 17, 17, 768)          0         ['activation_238[0][0]',      \n",
      "                                                                     'activation_241[0][0]',      \n",
      "                                                                     'activation_246[0][0]',      \n",
      "                                                                     'activation_247[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_252 (B  (None, 17, 17, 192)          576       ['conv2d_252[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_252 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_252[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_252[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_253 (B  (None, 17, 17, 192)          576       ['conv2d_253[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_253 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_253[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_253[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_249 (B  (None, 17, 17, 192)          576       ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_254 (B  (None, 17, 17, 192)          576       ['conv2d_254[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_249 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_249[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_254 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_254[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_249[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_254[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_250 (B  (None, 17, 17, 192)          576       ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_255 (B  (None, 17, 17, 192)          576       ['conv2d_255[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_250 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_250[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_255 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_255[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_24 (Aver  (None, 17, 17, 768)          0         ['mixed6[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_250[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_255[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)         (None, 17, 17, 192)          147456    ['average_pooling2d_24[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_248 (B  (None, 17, 17, 192)          576       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_251 (B  (None, 17, 17, 192)          576       ['conv2d_251[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_256 (B  (None, 17, 17, 192)          576       ['conv2d_256[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_257 (B  (None, 17, 17, 192)          576       ['conv2d_257[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_248 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_248[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_251 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_251[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_256 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_256[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_257 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_257[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 17, 17, 768)          0         ['activation_248[0][0]',      \n",
      "                                                                     'activation_251[0][0]',      \n",
      "                                                                     'activation_256[0][0]',      \n",
      "                                                                     'activation_257[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_260 (B  (None, 17, 17, 192)          576       ['conv2d_260[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_260 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_260[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_260[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_261 (B  (None, 17, 17, 192)          576       ['conv2d_261[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_261 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_261[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)         (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)         (None, 17, 17, 192)          258048    ['activation_261[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_258 (B  (None, 17, 17, 192)          576       ['conv2d_258[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_262 (B  (None, 17, 17, 192)          576       ['conv2d_262[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_258 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_258[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_262 (Activation  (None, 17, 17, 192)          0         ['batch_normalization_262[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)         (None, 8, 8, 320)            552960    ['activation_258[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)         (None, 8, 8, 192)            331776    ['activation_262[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_259 (B  (None, 8, 8, 320)            960       ['conv2d_259[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_263 (B  (None, 8, 8, 192)            576       ['conv2d_263[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_259 (Activation  (None, 8, 8, 320)            0         ['batch_normalization_259[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_263 (Activation  (None, 8, 8, 192)            0         ['batch_normalization_263[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 8, 8, 768)            0         ['mixed7[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, 8, 8, 1280)           0         ['activation_259[0][0]',      \n",
      "                                                                     'activation_263[0][0]',      \n",
      "                                                                     'max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)         (None, 8, 8, 448)            573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_268 (B  (None, 8, 8, 448)            1344      ['conv2d_268[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_268 (Activation  (None, 8, 8, 448)            0         ['batch_normalization_268[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)         (None, 8, 8, 384)            491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)         (None, 8, 8, 384)            1548288   ['activation_268[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_265 (B  (None, 8, 8, 384)            1152      ['conv2d_265[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_269 (B  (None, 8, 8, 384)            1152      ['conv2d_269[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_265 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_265[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_269 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_269[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_265[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_265[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_269[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_269[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (Aver  (None, 8, 8, 1280)           0         ['mixed8[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)         (None, 8, 8, 320)            409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_266 (B  (None, 8, 8, 384)            1152      ['conv2d_266[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_267 (B  (None, 8, 8, 384)            1152      ['conv2d_267[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_270 (B  (None, 8, 8, 384)            1152      ['conv2d_270[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_271 (B  (None, 8, 8, 384)            1152      ['conv2d_271[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)         (None, 8, 8, 192)            245760    ['average_pooling2d_25[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_264 (B  (None, 8, 8, 320)            960       ['conv2d_264[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_266 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_266[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_267 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_267[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_270 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_270[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_271 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_271[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_272 (B  (None, 8, 8, 192)            576       ['conv2d_272[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_264 (Activation  (None, 8, 8, 320)            0         ['batch_normalization_264[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, 8, 8, 768)            0         ['activation_266[0][0]',      \n",
      "                                                                     'activation_267[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 8, 8, 768)            0         ['activation_270[0][0]',      \n",
      " )                                                                   'activation_271[0][0]']      \n",
      "                                                                                                  \n",
      " activation_272 (Activation  (None, 8, 8, 192)            0         ['batch_normalization_272[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, 8, 8, 2048)           0         ['activation_264[0][0]',      \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate_4[0][0]',       \n",
      "                                                                     'activation_272[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)         (None, 8, 8, 448)            917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_277 (B  (None, 8, 8, 448)            1344      ['conv2d_277[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_277 (Activation  (None, 8, 8, 448)            0         ['batch_normalization_277[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)         (None, 8, 8, 384)            786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)         (None, 8, 8, 384)            1548288   ['activation_277[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_274 (B  (None, 8, 8, 384)            1152      ['conv2d_274[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_278 (B  (None, 8, 8, 384)            1152      ['conv2d_278[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_274 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_274[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_278 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_278[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_274[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_274[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_278[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_278[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (Aver  (None, 8, 8, 2048)           0         ['mixed9[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)         (None, 8, 8, 320)            655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_275 (B  (None, 8, 8, 384)            1152      ['conv2d_275[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_276 (B  (None, 8, 8, 384)            1152      ['conv2d_276[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_279 (B  (None, 8, 8, 384)            1152      ['conv2d_279[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_280 (B  (None, 8, 8, 384)            1152      ['conv2d_280[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)         (None, 8, 8, 192)            393216    ['average_pooling2d_26[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_273 (B  (None, 8, 8, 320)            960       ['conv2d_273[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_275 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_275[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_276 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_276[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_279 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_279[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_280 (Activation  (None, 8, 8, 384)            0         ['batch_normalization_280[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_281 (B  (None, 8, 8, 192)            576       ['conv2d_281[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_273 (Activation  (None, 8, 8, 320)            0         ['batch_normalization_273[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, 8, 8, 768)            0         ['activation_275[0][0]',      \n",
      "                                                                     'activation_276[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 8, 8, 768)            0         ['activation_279[0][0]',      \n",
      " )                                                                   'activation_280[0][0]']      \n",
      "                                                                                                  \n",
      " activation_281 (Activation  (None, 8, 8, 192)            0         ['batch_normalization_281[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, 8, 8, 2048)           0         ['activation_273[0][0]',      \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_5[0][0]',       \n",
      "                                                                     'activation_281[0][0]']      \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 2048)                 0         ['mixed10[0][0]']             \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  1049088   ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 512)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 20)                   10260     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22862132 (87.21 MB)\n",
      "Trainable params: 1059348 (4.04 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 574s 1s/step - loss: 2.1162 - accuracy: 0.3719 - val_loss: 1.4894 - val_accuracy: 0.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "500/500 [==============================] - 544s 1s/step - loss: 1.5227 - accuracy: 0.5428 - val_loss: 1.2750 - val_accuracy: 0.6217\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 547s 1s/step - loss: 1.3662 - accuracy: 0.5846 - val_loss: 1.2021 - val_accuracy: 0.6405\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2866 - accuracy: 0.6069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 74\u001b[0m\n\u001b[1;32m     68\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     69\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     70\u001b[0m     ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_food20_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m ]\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on validation performance\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset directory\n",
    "dataset_path = data_path\n",
    "\n",
    "# Image dimensions (299x299 for InceptionV3 or 224x224 for ResNet50)\n",
    "img_size = (299, 299)\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation and Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Split 20% for validation\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Load the InceptionV3 model with ImageNet weights, excluding the top layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(*img_size, 3))\n",
    "\n",
    "# Freeze all layers in the base model to retain pre-trained features\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(20, activation='softmax')(x)  # 20 categories for the output layer\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set up early stopping and model checkpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_food20_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Adjust based on validation performance\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last 30 layers of the base model\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust as needed\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
